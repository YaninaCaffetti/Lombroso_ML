{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52ae1d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /opt/anaconda3/lib/python3.8/site-packages (2.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d53b07ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SGD' from 'keras.optimizers' (/opt/anaconda3/lib/python3.8/site-packages/keras/optimizers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e156bd3d052b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdagrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdadelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNadam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'SGD' from 'keras.optimizers' (/opt/anaconda3/lib/python3.8/site-packages/keras/optimizers.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.python.keras.layers import  Convolution2D, MaxPooling2D\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import applications\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "from keras.callbacks import ModelCheckpoint, History  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import cv2\n",
    "import time\n",
    "import imutils\n",
    "import math\n",
    "from PIL import Image\n",
    "import time\n",
    "from keras.models import load_model\n",
    "from utils import *\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd41430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(/Lombroso_Script/Nato.png):\n",
    "    image0 = cv2.imread(/Lombroso_Script/Nato.png)\n",
    "    image0 = cv2.cvtColor(image0, cv2.COLOR_BGR2RGB)\n",
    "    return image0\n",
    "\n",
    "def plot_image(image0, title='Nato'):\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_title(title)\n",
    "    ax1.imshow(image0)\n",
    "    \n",
    "def read_image(/Lombroso_Script/LocoMoral.png):\n",
    "    image1 = cv2.imread(/Lombroso_Script/LocoMoral.png)\n",
    "    image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
    "    return image1\n",
    "\n",
    "def plot_image(image1, title='LocoMoral'):\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_title(title)\n",
    "    ax1.imshow(image1)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2a6b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faces(image0):\n",
    "    \"\"\"\n",
    "    Devuelve una matriz con las caras detectadas en una imagen.\n",
    "    Cada cara se define como lo hace OpenCV: x superior izquierda, y superior izquierda, ancho y alto.\n",
    "    \"\"\"\n",
    "    image_copy = np.copy(image0)\n",
    "    gray = cv2.cvtColor(image_copy, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    face_classifier = cv2.CascadeClassifier ('haarcascade_frontalface_alt.xml')\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.2, 5)\n",
    "    \n",
    "    return faces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4da6976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faces(image1):\n",
    "    image_copy = np.copy(image1)\n",
    "    gray = cv2.cvtColor(image_copy, cv2.COLOR_RGB2GRAY)\n",
    "    face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.2, 5)\n",
    "    \n",
    "    return faces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5df4e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_faces(image0, faces=None, plot=True):\n",
    "    \"\"\"\n",
    "    Traza una imagen con sus rostros detectados. Si no hay, también contabiliza.\n",
    "    \"\"\"\n",
    "    if faces is None:\n",
    "        faces = get_faces(image0)\n",
    "    image_with_faces = np.copy(image0)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(image_with_faces, (x,y), (x+w,y+h), (255,0,0), 3)\n",
    "        \n",
    "    if plot is True:\n",
    "        plot_image(image_with_faces)\n",
    "    else:\n",
    "        return image_with_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e21709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_faces(image1, faces=None, plot=True):\n",
    "    \"\"\"\n",
    "    Traza una imagen con sus rostros detectados. Si no hay, también contabiliza.\n",
    "    \"\"\"\n",
    "    if faces is None:\n",
    "        faces = get_faces(image1)\n",
    "    image_with_faces = np.copy(image1)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(image_with_faces, (x,y), (x+w,y+h), (255,0,0), 3)\n",
    "        \n",
    "    if plot is True:\n",
    "        plot_image(image_with_faces)\n",
    "    else:\n",
    "        return image_with_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afd0cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_with_keypoints(image0, image_info):\n",
    "    \"\"\"\n",
    "   Traza los puntos clave dados en formato (x, y)\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    \n",
    "    for (face, keypoints) in image_info:\n",
    "        for (x,y) in keypoints:\n",
    "            ax1.scatter(x, y, marker='o', c='c', s=10)\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "    ax1.imshow(image0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75b8ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_with_keypoints(image1, image_info):\n",
    "    \"\"\"\n",
    "   Traza los puntos clave dados en formato (x, y)\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    \n",
    "    for (face, keypoints) in image_info:\n",
    "        for (x,y) in keypoints:\n",
    "            ax1.scatter(x, y, marker='o', c='c', s=10)\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "    ax1.imshow(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7e0e603",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-acca7da785c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Lombroso_Script/Data/Entrenamiento/without_mask_1000.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Faces detected: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdraw_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_image' is not defined"
     ]
    }
   ],
   "source": [
    "image = read_image('Lombroso_Script/Data/Entrenamiento/without_mask_1000.jpg')\n",
    "faces = get_faces(image)\n",
    "print(\"Faces detected: {}\".format(len(faces)))\n",
    "draw_faces(image, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c52704c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ed8fd42c3494>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mplot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_data' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "'''Visualización de los datos de entrenamiento'''\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "for i in range(9):\n",
    "    ax = fig.add_subplot(3, 3, i + 1, xticks=[], yticks=[])\n",
    "    plot_data(X_train[i], y_train[i], ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "045e8782",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a8ba57a37a98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_train.shape == {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m print(\"y_train.shape == {}; y_train.min == {:.3f}; y_train.max == {:.3f}\".format(\n\u001b[1;32m      4\u001b[0m     y_train.shape, y_train.min(), y_train.max()))\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_data' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_data()\n",
    "print(\"X_train.shape == {}\".format(X_train.shape))\n",
    "print(\"y_train.shape == {}; y_train.min == {:.3f}; y_train.max == {:.3f}\".format(\n",
    "    y_train.shape, y_train.min(), y_train.max()))\n",
    "\n",
    "X_test, _ = load_data(test=True)\n",
    "print(\"X_test.shape == {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69ea97f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 96, 96, 16)        80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                7710      \n",
      "=================================================================\n",
      "Total params: 137,806\n",
      "Trainable params: 137,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Red Convolucional de Keras.\n",
    "\n",
    "shape = (96,96)\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(16,(2,2),padding='same',input_shape=(96,96, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=3))\n",
    "\n",
    "model.add(Convolution2D(32,(3,3),padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=3))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Convolution2D(64,(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=3))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Convolution2D(128,(3,3),padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=3))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(30))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2feedee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a2f6fe22790a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m def plot_keypoints(img_path, \n\u001b[0;32m---> 37\u001b[0;31m                   \u001b[0mface_cascade\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'haarcascade_frontalface_alt.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                   model_path='my_model.h5'):\n\u001b[1;32m     39\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_data(test=False):\n",
    " \n",
    "    FTRAIN = 'data/training.csv'\n",
    "    FTEST = 'data/test.csv'\n",
    "    fname = FTEST if test else FTRAIN\n",
    "    df = read_csv(os.path.expanduser(fname))  \n",
    "\n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "\n",
    "    df = df.dropna()  \n",
    "\n",
    "    X = np.vstack(df['Image'].values) / 255.  \n",
    "    X = X.astype(np.float32)\n",
    "    X = X.reshape(-1, 96, 96, 1)\n",
    "\n",
    "    if not test:  \n",
    "        y = df[df.columns[:-1]].values\n",
    "        y = (y - 48) / 48  \n",
    "        X, y = shuffle(X, y, random_state=42) \n",
    "        y = y.astype(np.float32)\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def plot_data(img, landmarks, axis):\n",
    "   \n",
    "    axis.imshow(np.squeeze(img), cmap='gray') \n",
    "    landmarks = landmarks * 48 + 48 \n",
    "    axis.scatter(landmarks[0::2], \n",
    "        landmarks[1::2], \n",
    "        marker='o', \n",
    "        c='c', \n",
    "        s=40)\n",
    "\n",
    "def plot_keypoints(img_path, \n",
    "                  face_cascade=cv2.CascadeClassifier('haarcascade_frontalface_alt.xml'),\n",
    "                  model_path='my_model.h5'):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = fig.add_subplot(1, 1, 1, xticks=[], yticks=[])\n",
    "    ax.imshow(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        plt.title('no faces detected')\n",
    "    elif len(faces) > 1:\n",
    "        plt.title('too many faces detected')\n",
    "        for (x,y,w,h) in faces:\n",
    "            rectangle = cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "            ax.imshow(cv2.cvtColor(rectangle, cv2.COLOR_BGR2RGB))\n",
    "    elif len(faces) == 1:\n",
    "        plt.title('one face detected')\n",
    "        x,y,w,h = faces[0]\n",
    "        bgr_crop = img[y:y+h, x:x+w] \n",
    "        orig_shape_crop = bgr_crop.shape\n",
    "        gray_crop = cv2.cvtColor(bgr_crop, cv2.COLOR_BGR2GRAY)\n",
    "        resize_gray_crop = cv2.resize(gray_crop, (96, 96)) / 255.\n",
    "        model = load_model(model_path)\n",
    "        landmarks = np.squeeze(model.predict(\n",
    "            np.expand_dims(np.expand_dims(resize_gray_crop, axis=-1), axis=0)))\n",
    "        ax.scatter(((landmarks[0::2] * 48 + 48)*orig_shape_crop[0]/96)+x, \n",
    "                   ((landmarks[1::2] * 48 + 48)*orig_shape_crop[1]/96)+y, \n",
    "                   marker='o', c='c', s=40)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a2dd074",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'History' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-17117c179496>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhisto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'History' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "histo = History()\n",
    "\n",
    "def compile_model(model, epochs):\n",
    "    \n",
    "    filepath = 'model.hdf5'\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath=filepath, \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_split=0.2,\n",
    "              epochs=epochs, batch_size=20, callbacks=[checkpointer, histo], verbose=1)\n",
    "    \n",
    "    model.save(filepath)\n",
    "    \n",
    "    return hist\n",
    "\n",
    "def show_training_validation_loss(hist, epochs):\n",
    "    plt.plot(range(epochs), hist.history[\n",
    "             'val_loss'], 'g-', label='Val Loss')\n",
    "    plt.plot(range(epochs), hist.history[\n",
    "             'loss'], 'g--', label='Train Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show() \n",
    "\n",
    "train_net = False\n",
    "\n",
    "if train_net is True:\n",
    "    hist = compile_model(model, epochs) \n",
    "else:\n",
    "    model.load_weights('model.hdf5')\n",
    "    \n",
    "\n",
    "if train_net is True:\n",
    "    show_training_validation_loss(hist, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74c494e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-5d1cb2955648>, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-5d1cb2955648>\"\u001b[0;36m, line \u001b[0;32m35\u001b[0m\n\u001b[0;31m    def show_image_and_features(/Lombroso_Script/Nato.png):\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_keypoints(image, faces=None):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    if faces is None:\n",
    "        faces = get_faces(image)\n",
    "    faces_shape = (96, 96)\n",
    "    image_copy = np.copy(image)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        face = image_copy[y:y+h,x:x+w]\n",
    "        gray_face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        resize_gray_face = cv2.resize(gray_face, faces_shape) / 255\n",
    "        inputs = np.expand_dims(np.expand_dims(resize_gray_face, axis=-1), axis=0)\n",
    "                                                     \n",
    "        predicted_keypoints = model.predict(inputs)\n",
    "        predicted_keypoints = np.squeeze(predicted_keypoints)\n",
    "        \n",
    "        keypoints = []        \n",
    "        for idx in range(0, len(predicted_keypoints), 2):\n",
    "            x_scale_factor = face.shape[0]/faces_shape[0] \n",
    "            y_scale_factor = face.shape[1]/faces_shape[1] \n",
    "            x_center_left_offset = predicted_keypoints[idx] * faces_shape[0]/2 + faces_shape[0]/2 \n",
    "            y_center_left_offset = predicted_keypoints[idx + 1] * faces_shape[1]/2 + faces_shape[1]/2\n",
    "            \n",
    "            x_center = int(x + (x_scale_factor * x_center_left_offset))\n",
    "            y_center = int(y + (y_scale_factor * y_center_left_offset))\n",
    "\n",
    "            keypoints.append([x_center, y_center])\n",
    "        \n",
    "        result.append([(x,y,w,h), keypoints])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def show_image_and_features(/Lombroso_Script/Nato.png):\n",
    "    image0 = read_image(/Lombroso_Script/Nato.png)\n",
    "    faces = get_faces(image0)\n",
    "    keypoints = get_keypoints(image0, faces)\n",
    "    image_with_faces = draw_faces(image0, faces ,plot=False)\n",
    "    plot_image_with_keypoints(image_with_faces, keypoints)\n",
    "\n",
    "show_image_and_features('/Lombroso_Script/Nato.png')\n",
    "\n",
    "\n",
    "def show_image_and_features(/Lombroso_Script/LocoMoral.png):\n",
    "    image1 = read_image(/Lombroso_Script/LocoMoral.png)\n",
    "    faces = get_faces(image1)\n",
    "    keypoints = get_keypoints(image1, faces)\n",
    "    image_with_faces = draw_faces(image1, faces ,plot=False)\n",
    "    plot_image_with_keypoints(image_with_faces, keypoints)\n",
    "\n",
    "show_image_and_features('/Lombroso_Script/LocoMoral.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4af8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
